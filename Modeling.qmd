---
title: "ST 558 Project 3: Modeling"
author: "Lamia Benyamine"
date: "July 29, 2024"
format: html
editor: visual
---

# Introduction

This data is based on Behavioral Risk Factor Surveillance System (BRFSS) survey conducted  on over 400,000 Americans by the CDC in 2015. This data set as been cleaned and contains 253,680 responses and has a target variable Diabetes_binary with 2 classes: 0 is for no diabetes and 1 is for prediabetes or diabetes.

The main important risk factors we will be investigating are: High Blood Pressure, High Cholesterol, Sex, Age, General Health score, Income, Physical Activity (physical activity in past 30 days - not including job), Fruits (consume fruit daily), Veggies (consume vegetables daily), Smoker (at least 100 cigarets in your life), Stroke (ever had a stroke), Heart Disease or Attack (coronary heart disease (CHD) or myocardial infarction (MI)), Heavy Alcohol Consumption (adult men having 14+ drinks/week and women having 7+ drinks/week), and Body Mass Index (BMI).

# Models

This analysis will create models for predicting the Diabetes variable using the caret package. We will split the data and create multiple models of each logistic regression, classification tree, and a random forest fit using the training set. Then we will use logLoss as the metric and a five-fold cross-validation to evaluate and select the best fit from each prediction model. Then we will test the final three models using the testing set.

Five-fold cross validation partitions the data into five non-overlapping partitions. For each one of the partitions, a model is trained on 70% of the data, and evaluated on the remaining 30% of the data. We will end up with five metrics for each test set evaluation and average these to give an estimate of how well our model will perform on future data.

Log loss is a common loss function and is also used as a metric to compare models. Log loss estimates how accurate the prediction probability (p) is to the corresponding actual value (y).

$$
logLoss = -\frac{1}{N} \sum[y_ilnp_i + (1-y_i)ln(1-p_i)]
$$

The higher log loss value, the more the prediction model differs from the actual value. A log loss value is calculated for each observation (i) both actual and prediction, and then a negative average is taken across all observations (N) to get a model log loss value. This metric is better than using accuracy because accuracy is the count of predictions where the predicted value equals the actual value. Whereas log loss takes into account the bias of the prediction based on the variance from the actual label. This gives us a better look into the performance of the model.

## Split the Data

Load libraries necessary for this analysis.

```{r, message = FALSE, warning = FALSE}
library(readr)
library(tidyverse)
library(dplyr)
library(caret)
library(ranger) #Used for a faster implementation of Random Forests 
```

Read in the diabetes data using a relative path, and convert any variables to a factor if needed.

```{r}
diabetes_tb <- read_csv("data/diabetes_binary_health_indicators_BRFSS2015.csv", show_col_types = FALSE) |>
                select(-c(CholCheck, MentHlth, DiffWalk, NoDocbcCost, Education, PhysHlth)) |>
                mutate(across(-c(Diabetes_binary, BMI, GenHlth, Sex, Age, Income), \(x) factor(x, levels = c("0","1"), labels = c("No", "Yes"))),
                       Diabetes = factor(Diabetes_binary, levels = c(0:1), labels = c("no diabetes", "diabetes")),
                       GenHlth = factor(GenHlth, levels = c(1:5), labels = c("excellent", "very good", "good", "fair", "poor")),
                       Sex = factor(Sex, levels = c("0", "1"), labels = c("Female", "Male")),
                       Age = factor(Age, levels = c(1:13), labels=c("18-24", "25-34", "25-34", "35-44", "35-44", "45-54", "45-54", "55-64", "55-64", "65-74", "65-74", "75+", "75+")),
                       Income = factor(Income, levels = c(1:8), labels = c("less than $10k","less than $35k", "less than $35k", "less than $35k", "less than $35k", "less than $75k", "less than $75k", "more than $75k" ))) |>
                select(-Diabetes_binary)
```

Create dummy columns corresponding to the categorical variables for use in our models.

```{r}
newCols <- dummyVars(~ Sex + Age + GenHlth + HighBP + HighChol + Income, data = diabetes_tb) |>
predict(newdata = diabetes_tb)
#add those and remove originals
diabetes_tb <- cbind(diabetes_tb, newCols)

#add '-' to variables that have spaces in their levels in order to run the regression models
levels(diabetes_tb$Diabetes) <- gsub("[^[:alnum:]]", "_", levels(diabetes_tb$Diabetes))
levels(diabetes_tb$Income) <- gsub("[^[:alnum:]]", "_", levels(diabetes_tb$Income))
levels(diabetes_tb$GenHlth) <- gsub("[^[:alnum:]]", "_", levels(diabetes_tb$GenHlth))
```

Split your data into a training and test set with 70:30 ratio.

```{r}
#Set seed to get the same training and test set each time
set.seed(99)
split <- createDataPartition(y = diabetes_tb$Diabetes, p = 0.7, list = FALSE)
head(split)

#Training set receives 70% of data
train <- diabetes_tb[split, ]
#Testing set receives 30% of data
test <- diabetes_tb[-split, ]
```

## Logistic Regression Models

A logistic regression model is used for qualitative response variables and estimates the probability that the response belongs to a particular category. It is best used for a response variable with two classes and can only take on values on the real line which is perfect for binary variables. This data sets response variable is 'Diabetes' which has a binary classification of 0 for no diabetes and 1 for diabetes. Using maximum likelihood estimation, different values of the coefficient are tested through multiple iterations to optimize the best fit of log odds.

We will fit three models using this method and determine the model with the best fit.

```{r}
#Fit all predictor variables
logRegFit1 <- train(Diabetes ~ Sex + Age + GenHlth + HighBP + HighChol + Income + PhysActivity + Fruits + Veggies + Smoker + Stroke + HeartDiseaseorAttack + BMI + HvyAlcoholConsump + AnyHealthcare,
                  data = train,
                  method = "glm",
                  family = "binomial",
                  metric = "logLoss",
                  trControl = trainControl(method = "cv", number = 5,
                                          classProbs = TRUE, summaryFunction = mnLogLoss))
logRegFit1

#Fit main variables based on EDA
logRegFit2 <- train(Diabetes ~ Sex + Age + GenHlth + HighBP + HighChol + Income + BMI,
                  data = train,
                  method = "glm",
                  family = "binomial",
                  metric = "logLoss",
                  trControl = trainControl(method = "cv", number = 5,
                                          classProbs = TRUE, summaryFunction = mnLogLoss))
logRegFit2

#Fit using interactions
logRegFit3 <- train(Diabetes ~ Sex*Age*BMI + GenHlth + HighBP + HighChol + Income,
                  data = train,
                  method = "glm",
                  family = "binomial",
                  metric = "logLoss",
                  trControl = trainControl(method = "cv", number = 5,
                                          classProbs = TRUE, summaryFunction = mnLogLoss))
logRegFit3
```
Based on the logloss metric, the first logical regression fit has the lowest log loss, and thus the best model.

## Classification Tree

A classification tree model is decision tree for binary response variables. The observed data is grouped based on the number of possible combinations of levels of the categorical variables. At each node of the tree, there is a condition involving a variable and a cut-off to divide the observations in two groups. Repeating this process for each variable creates a full tree, then the tree gets pruned to be the optimal model. Cross-validation is used to determine how many nodes the best model tree should have. 

We will fit a classification tree with varying values of the complexity parameter and determine the best model.

```{r}
classTreeFit <- train(Diabetes ~ Sex + Age + GenHlth + HighBP + HighChol + Income + PhysActivity + Fruits + Veggies + Smoker + Stroke + HeartDiseaseorAttack + BMI + HvyAlcoholConsump + AnyHealthcare,
                  data = train,
                  method = "rpart",
                  metric = "logLoss",
                  trControl = trainControl(method = "cv", number = 5,
                                          classProbs = TRUE, summaryFunction = mnLogLoss))
classTreeFit
```

Based on the logloss metric and the lowest complexity parameter, the optimal classification tree model has a cp of 0.0008487249.

## Random Forest

A random forest model is a collection of decision trees. It uses the same idea as bagging and creates multiple trees based on bootstrap samples from the training data. There is no pruning involved, but each tree is grown until the number of observations in each node is no more than size m. So each individual tree will overfit the data in a different way and when we average the predictions from different trees, the overfitting will be removed. This model is a special case of bagging where m=p. There are 11 classification variables so m = 11

We will fit a a random forest model and determine the best model. 

```{r}
m <- c(1:11)
split <- c("extratrees")
min.node <- c(100)
rfGrid <- expand.grid(mtry = m, splitrule = split, min.node.size = min.node)

randForFit <- train(Diabetes ~ Sex + Age + GenHlth + HighBP + HighChol + Income + PhysActivity + Veggies  + Stroke + HeartDiseaseorAttack + BMI,
                  data = train,
                  method = "ranger",
                  metric = "logLoss",
                  num.trees = 100,
                  trControl = trainControl(method = "cv", number = 5,
                                          classProbs = TRUE, summaryFunction = mnLogLoss),
                  tuneGrid = rfGrid)

randForFit
```

Based on the lowest logloss, the best random forest model had mtry = 8.

# Compare models

With the three best models from the above analysis, we will compare them using the test set and determine the best overall model.

```{r}
logPred <- confusionMatrix(data = test$Diabetes, reference = predict(logRegFit1, newdata = test))
classPred <- confusionMatrix(data = test$Diabetes, reference = predict(classTreeFit, newdata = test))
randPred <- confusionMatrix(data = test$Diabetes, reference = predict(randForFit, newdata = test))

#Attempt at using logloss for prediction results
#logPred <-- mnLogLoss(data = test$Diabetes, reference = predict(logRegFit1, newdata = test))


#Summary table to determine the best model
fitStats <- data.frame(logPred$overall, classPred$overall, randPred$overall)
fitStats[1,]
```

Based on the accuracy from using the test set, the logistic regression is the best model for this data.